Deep Dive into Kafka Producers
------------------------------
Kafka can be used as a message queue, message bus, or data storage system.

-> Bootstrapping Kafka broker URLs: The Producer connects to at least one broker to fetch metadata about the Kafka cluster. It may happen that the first broker to which the producer wants to connect may be down. To ensure a failover, the producer implementation takes a list of more than one broker URL to bootstrap from. Producer iterates through a list of Kafka broker addresses until it finds the one to connect to fetch cluster metadata.

-> Data Serialization: Kafka producer serializes every message data object into ByteArrays before sending any record to the respective broker over the wire. Similarly, it converts any byte sequence received from the broker as a response to the message object.

-> Determining the leader of the partition: Producers send data to the leader of the partition directly. It is the producer's responsibility to determine the leader of the partition to which it will write messages. To do so, producers ask for metadata from any of the Kafka brokers.

-> Failure handling/retry ability: Handling failure responses or number of retries is something that needs to be controlled through the producer application. You can configure the number of retries through Producer API configuration.

-> Batching: For efficient message transfers, batching is a very useful mechanism.Through Producer API configurations, you can control whether you need to use the producer in asynchronous mode or not. Batching ensures reduced I/O and optimum utilization of producer memory.

Required configuration: In most applications, we first start with creating the initial configuration without which we cannot run the application. The following are three mandatory configuration parameters:

--bootstrap.servers: This contains a list of Kafka brokers addresses. The address is specified in terms of hostname:port. We can specify one or more broker detail, but we recommend that you provide at least two so that if one broker goes down, producer can use the other on

--key.serializer: The message is sent to Kafka brokers in the form of a keyvalue pair. Brokers expect this key-value to be in byte arrays. So we need to tell
 producer which serializer class is to be used to convert this key-value object to a byte array. This property is set to tell the producer which class to use to serialize the key of the message.
Kafka provides us with three inbuilt serializer classes: ByteArrayserializer, StringSerializer, and IntegerSerializer.
All these classes are present in the org.apache.kafka.common.serialization package and implement the serializer interface.

--value.serializer:This is similar to the key.serializer property, but this property tells the producer which class to use in order to serialize the value. You
can implement your own serialize class and assign to this property

Additional producer configuration
---------------------------------
buffer.memory: This is the amount of memory that producer can use to buffer a message that is waiting to be sent to the Kafka server. In simple terms, it is the total memory that is available to the Java producer to collect unsent messages.

When this limit is reached, the producer will block the messages for max.block.ms: before raising an exception. If your batch size is more, allocate more memory to the producer buffer.

Additionally, to avoid keeping records queued indefinitely, you can set a timeout using request.timeout.ms. If this timeout expires before a message can be successfully sent, then it will be removed from the queue and an exception will be thrown.

acks: This configuration helps in configuring when producer will receive acknowledgment from the leader before considering that the message is committed successfully:

acks=0: Producer will not wait for any acknowledgment from the server. Producer will not know if the message is lost at any point in time and is not committed by the leader broker. Note that no retry will happen in this case and the message will be completely lost. This can be used when you want to achieve very high throughput and when you don't care about potential message loss.

acks=1: Producer will receive an acknowledgment as soon as the leader has written the message to its local log. If the leader fails to write the message to its log, producer will retry sending the data according to the retry policy set and avoid potential loss of messages. However, we can still have message loss in a scenario where the leader acknowledges to producer but does not replicate the message to the other broker before it goes down.

acks=all: Producer will only receive acknowledgment when the leader has received acknowledgment for all the replicas successfully. This is a safe setting where we cannot lose data if the replica number is sufficient to avoid such failures. Remember,throughput will be lesser then the first two settings.

batch.size: This setting allows the producer to batch the messages based on the partition up to the configured amount of size. When the batch reaches the limit, all messages in the batch will be sent. However, it's not necessary that producer wait for the batch to be full. It sends the batch after a specific time interval without worrying about the number of messages in the batch

linger.ms: This represents an amount of time that a producer should wait for additional messages before sending a current batch to the broker. Kafka producer waits for the batch to be full or the configured linger.ms time; if any condition is met, it will send the batch to brokers. Producer will wait till the configured amount of time in milliseconds for any additional messages to get added to the current batch.

compression.type: By default, producer sends uncompressed messages to brokers. When sending a single message, it will not make that much sense, but when we use batches, it's good to use compression to avoid network overhead and increase throughput. The available compressions are GZIP, Snappy, or LZ4.
Remember that more batching would lead to better compression.

retires: If message sending fails, this represents the number of times producer will retry sending messages before it throws an exception. It is irrespective of reseeding a message after receiving an exception.

max.in.flight.request.per.connection: This is the number of messages producer can send to brokers without waiting for a response. If you do not care about the order of the messages, then setting its value to more than 1 will increase throughput. However, ordering may change if you set it to more than 1 with retry enabled.

timeout.ms: This is the amount of time a leader will wait for its followers to acknowledge the message before sending an error to producer. This setting will only help when acks is set to all.